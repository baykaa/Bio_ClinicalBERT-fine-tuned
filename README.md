# Toxicity Detection in Online Comments

This project focuses on detecting and classifying toxic comments using machine learning models. The goal is to identify harmful online content efficiently and accurately, aiding content moderation and fostering healthier online interactions.

# Objective: 

Develop and evaluate a model to classify comments as "Toxic" or "Non-toxic" using advanced NLP techniques.
Dataset: Utilizes a public dataset from Civil Comments, extended by Jigsaw with additional labels for toxicity and identity mentions.
Model: Implements the pre-trained unitary/toxic-bert model for text classification.


# Steps:
1. Preprocess data (cleaning, tokenization, etc.).

2. Train and predict toxicity using a BERT-based pipeline.

3. Evaluate performance through accuracy and confusion matrix analysis.

4. Results: Achieved a classification accuracy of 80.50%, with performance insights from the confusion matrix.

# Tools Used:
NLP: transformers, nltk, datasets
Visualization: seaborn, matplotlib
Evaluation: sklearn
